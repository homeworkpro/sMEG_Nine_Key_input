{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mediterranean-jacksonville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fist1.csv', 'fist2.csv', 'fist3.csv', 'fist4.csv', 'fist5.csv', 'fist6.csv', 'forefinger1.csv', 'forefinger2.csv', 'forefinger3.csv', 'forefinger4.csv', 'forefinger5.csv', 'forefinger6.csv', 'forefinger7.csv', 'forefinger8.csv', 'forefinger9.csv', 'indexfinger1.csv', 'indexfinger2.csv', 'indexfinger3.csv', 'indexfinger4.csv', 'indexfinger5.csv', 'indexfinger6.csv', 'indexfinger7.csv', 'indexfinger8.csv', 'indexfinger9.csv', 'littlefinger1.csv', 'littlefinger2.csv', 'littlefinger3.csv', 'littlefinger4.csv', 'littlefinger5.csv', 'littlefinger6.csv', 'littlefinger7.csv', 'littlefinger8.csv', 'middlefinger1.csv', 'middlefinger2.csv', 'middlefinger3.csv', 'middlefinger4.csv', 'middlefinger5.csv', 'middlefinger6.csv', 'middlefinger7.csv', 'middlefinger8.csv', 'middlefinger9.csv', 'thumb1.csv', 'thumb2.csv', 'thumb3.csv', 'thumb4.csv', 'thumb5.csv', 'thumb6.csv']\n"
     ]
    }
   ],
   "source": [
    "#Insert dataset\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import h5py\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, BatchNormalization,concatenate, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from emg import EMG_filter\n",
    "\n",
    "def get_files_in_directory(path, extension):\n",
    "    os.chdir(path)\n",
    "    result = glob.glob('*.{}'.format(extension))\n",
    "    result.sort() # Ensure correct order of files\n",
    "    return result\n",
    "def array_from_csv(file):\n",
    "    list_arr = pd.read_csv(file, sep=',', header=0,skiprows=2).values\n",
    "    return list_arr\n",
    "list_files = get_files_in_directory('C:/Users/Administrator/Desktop/MyoFile/right_hand2/', 'csv')\n",
    "print(list_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sharing-programmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(544, 120, 3)\n",
      "(544,)\n"
     ]
    }
   ],
   "source": [
    "#Insert dataset, 截取, add label\n",
    "interval = 100\n",
    "data = []\n",
    "label = []\n",
    "for file in list_files:\n",
    "    dataset = array_from_csv(file)\n",
    "    #emg = dataset[100:,0:3]\n",
    "    emg = dataset[100:, 3:6]\n",
    "    #emg2 = dataset[100:,2]\n",
    "    #截取数据\n",
    "    for j in range(0,len(emg)-len(emg)%interval,interval):\n",
    "        sample=[]\n",
    "        for i in range(interval):\n",
    "            channel = []\n",
    "            channel.append(emg[j+i][0])\n",
    "            channel.append(emg[j+i][1])\n",
    "            channel.append(emg[j+i][2])\n",
    "            sample.append(channel)\n",
    "        for i in range(120-interval):\n",
    "            sample.append([0,0,0])\n",
    "        data.append(sample)\n",
    "        if(\"thumb\" in file):\n",
    "            label.append(0)\n",
    "        elif(\"forefinger\" in file):\n",
    "            label.append(1)\n",
    "        elif(\"middlefinger\" in file):\n",
    "            label.append(2)\n",
    "        elif(\"indexfinger\" in file):\n",
    "            label.append(3)\n",
    "        elif(\"littlefinger\" in file):\n",
    "            label.append(4)\n",
    "        elif(\"fist\" in file):\n",
    "            label.append(5)\n",
    "data = np.asarray(data)\n",
    "label = np.asarray(label)\n",
    "print(data.shape)\n",
    "print(label.shape)        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "indonesian-penetration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (435, 120, 3, 1)\n",
      "Y_train shape: (435, 6)\n",
      "X_test shape: (109, 120, 3, 1)\n",
      "Y_test shape: (109, 6)\n",
      "[[0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def convert_to_one_hot(Y,C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "#随机打乱数据和标签\n",
    "N = data.shape[0]\n",
    "index = np.random.permutation(N)\n",
    "data = data[index,:,:]\n",
    "label = label[index]\n",
    "\n",
    "#对数据升维，标签one-hot\n",
    "data = np.expand_dims(data,axis=3)\n",
    "label = convert_to_one_hot(label,6).T\n",
    "#划分数据集\n",
    "N = data.shape[0]\n",
    "num_train = round(N*0.8)\n",
    "X_train = data[0:num_train,:,:,:]\n",
    "Y_train = label[0:num_train,:]\n",
    "X_test = data[num_train:N,:,:,:]\n",
    "Y_test = label[num_train:N,:]\n",
    "\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aging-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "#写一个LossHistory类，保存loss和acc\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch':[], 'epoch':[]}\n",
    "        self.accuracy = {'batch':[], 'epoch':[]}\n",
    "        self.val_loss = {'batch':[], 'epoch':[]}\n",
    "        self.val_acc = {'batch':[], 'epoch':[]}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('acc'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('accuracy'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_accuracy'))\n",
    "\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        plt.figure()\n",
    "        # acc\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
    "        # loss\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "brilliant-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(input_shape=(120,3,1), classes=6): \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = Conv2D(filters=32, kernel_size=(20,3), strides=(1,1), activation='relu', padding='same')(X_input)\n",
    "    X = MaxPooling2D((20,1))(X)\n",
    "\n",
    "    X = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(X)\n",
    "    X = MaxPooling2D((2,1),)(X)\n",
    "    \n",
    "    X = Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu',padding='valid')(X)\n",
    "    \n",
    "    X = Flatten(name='flatten')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(128,activation='relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    model = Model(inputs=X_input, outputs=X)\n",
    "    return model\n",
    "    \n",
    "#model = CNN()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "valued-oliver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 120, 3, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 101, 1, 32)   1952        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 105, 1, 32)   1568        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 109, 1, 32)   1184        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 113, 1, 32)   800         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 6, 1, 32)     0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 6, 1, 32)     0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 6, 1, 32)     0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 6, 1, 32)     0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 4, 1, 64)     6208        max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 3, 1, 64)     8256        max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 2, 1, 64)     10304       max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 1, 1, 64)     12352       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 1, 1, 64)     0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 1, 1, 64)     0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 1, 1, 64)     0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 1, 1, 64)     0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 64)           0           max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 64)           0           max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 64)           0           max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 64)           0           max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256)          0           flatten_8[0][0]                  \n",
      "                                                                 flatten_9[0][0]                  \n",
      "                                                                 flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          32896       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 6)            774         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 76,294\n",
      "Trainable params: 76,294\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def ML_CNN(input_shape=(120,3,1), classes=6): \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    f1 = [20, 16, 12, 8]\n",
    "    f2 = [3, 4, 5, 6]\n",
    "    convs = []\n",
    "    \n",
    "    for i in range(4):\n",
    "        x = Conv2D(filters=32, kernel_size=(f1[i],3),strides=(1,1), activation='relu',padding='valid')(X_input)\n",
    "        x = MaxPooling2D((20,1),padding=\"SAME\")(x)\n",
    "        \n",
    "        x = Conv2D(filters=64, kernel_size=(f2[i],1), strides=(1,1), activation='relu', padding='valid')(x)\n",
    "        x = MaxPooling2D((9-2-i,1),padding=\"SAME\")(x)\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        convs.append(x)\n",
    "        \n",
    "    merge = concatenate(convs,axis=1)\n",
    "    X = merge\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(128,activation='relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    model = Model(inputs=X_input, outputs=X)\n",
    "    return model\n",
    "    \n",
    "model = ML_CNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "motivated-clear",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14/14 [==============================] - 1s 16ms/step - loss: 33.5670 - accuracy: 0.1972 - val_loss: 2.7972 - val_accuracy: 0.5229\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.5203 - accuracy: 0.2905 - val_loss: 1.6635 - val_accuracy: 0.5963\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.4142 - accuracy: 0.3360 - val_loss: 1.0126 - val_accuracy: 0.6514\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 4.1322 - accuracy: 0.3749 - val_loss: 0.8533 - val_accuracy: 0.6789\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2.9960 - accuracy: 0.3875 - val_loss: 0.9357 - val_accuracy: 0.6881\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2.9699 - accuracy: 0.3944 - val_loss: 0.8552 - val_accuracy: 0.6606\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2.0483 - accuracy: 0.5120 - val_loss: 0.8103 - val_accuracy: 0.6972\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.9456 - accuracy: 0.4924 - val_loss: 0.8333 - val_accuracy: 0.6789\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.6675 - accuracy: 0.5220 - val_loss: 0.8087 - val_accuracy: 0.7064\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.4534 - accuracy: 0.5805 - val_loss: 0.7618 - val_accuracy: 0.7248\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.1944 - accuracy: 0.5528 - val_loss: 0.7481 - val_accuracy: 0.7156\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.3608 - accuracy: 0.5994 - val_loss: 0.6648 - val_accuracy: 0.8073\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.2017 - accuracy: 0.6171 - val_loss: 0.6186 - val_accuracy: 0.8073\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.2078 - accuracy: 0.5902 - val_loss: 0.6569 - val_accuracy: 0.7706\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.3497 - accuracy: 0.5820 - val_loss: 0.6306 - val_accuracy: 0.7982\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.1156 - accuracy: 0.6126 - val_loss: 0.6775 - val_accuracy: 0.7523\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.0502 - accuracy: 0.6241 - val_loss: 0.6121 - val_accuracy: 0.7982\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.1061 - accuracy: 0.6454 - val_loss: 0.6097 - val_accuracy: 0.7615\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.9762 - accuracy: 0.6542 - val_loss: 0.5635 - val_accuracy: 0.8257\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.9817 - accuracy: 0.6602 - val_loss: 0.5842 - val_accuracy: 0.7798\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.8770 - accuracy: 0.6593 - val_loss: 0.5778 - val_accuracy: 0.7798\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.7930 - accuracy: 0.7359 - val_loss: 0.5820 - val_accuracy: 0.7798\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.7422 - accuracy: 0.7539 - val_loss: 0.5291 - val_accuracy: 0.8257\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.8564 - accuracy: 0.7048 - val_loss: 0.5650 - val_accuracy: 0.7706\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.8857 - accuracy: 0.6983 - val_loss: 0.5161 - val_accuracy: 0.8349\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.7803 - accuracy: 0.7233 - val_loss: 0.5153 - val_accuracy: 0.7982\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.7574 - accuracy: 0.7046 - val_loss: 0.5022 - val_accuracy: 0.7982\n",
      "Epoch 28/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.6831 - accuracy: 0.7483 - val_loss: 0.4458 - val_accuracy: 0.8440\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.7615 - accuracy: 0.7361 - val_loss: 0.4941 - val_accuracy: 0.8073\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.7830 - accuracy: 0.7152 - val_loss: 0.5211 - val_accuracy: 0.7982\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.7232 - accuracy: 0.7391 - val_loss: 0.4418 - val_accuracy: 0.8440\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.6962 - accuracy: 0.7431 - val_loss: 0.4611 - val_accuracy: 0.8349\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.6829 - accuracy: 0.7596 - val_loss: 0.4414 - val_accuracy: 0.8440\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5963 - accuracy: 0.7794 - val_loss: 0.4587 - val_accuracy: 0.7982\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.6409 - accuracy: 0.7372 - val_loss: 0.5114 - val_accuracy: 0.8165\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5768 - accuracy: 0.7577 - val_loss: 0.4795 - val_accuracy: 0.8165\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.6914 - accuracy: 0.7543 - val_loss: 0.4415 - val_accuracy: 0.8257\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.6299 - accuracy: 0.7792 - val_loss: 0.4494 - val_accuracy: 0.8073\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5554 - accuracy: 0.7761 - val_loss: 0.5025 - val_accuracy: 0.8349\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5683 - accuracy: 0.8026 - val_loss: 0.4077 - val_accuracy: 0.8807\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.6375 - accuracy: 0.7767 - val_loss: 0.4525 - val_accuracy: 0.8440\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5896 - accuracy: 0.7941 - val_loss: 0.4213 - val_accuracy: 0.8440\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5349 - accuracy: 0.7940 - val_loss: 0.4000 - val_accuracy: 0.8532\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5143 - accuracy: 0.8138 - val_loss: 0.3698 - val_accuracy: 0.8624\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5269 - accuracy: 0.8348 - val_loss: 0.3983 - val_accuracy: 0.8532\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5704 - accuracy: 0.7651 - val_loss: 0.4264 - val_accuracy: 0.8440\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.6724 - accuracy: 0.8019 - val_loss: 0.3822 - val_accuracy: 0.8716\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.8333 - val_loss: 0.3676 - val_accuracy: 0.8624\n",
      "Epoch 49/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.8145 - val_loss: 0.3618 - val_accuracy: 0.8532\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5679 - accuracy: 0.8028 - val_loss: 0.3995 - val_accuracy: 0.8165\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.6422 - accuracy: 0.7960 - val_loss: 0.4268 - val_accuracy: 0.8349\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5246 - accuracy: 0.8103 - val_loss: 0.3456 - val_accuracy: 0.8807\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.8223 - val_loss: 0.4244 - val_accuracy: 0.8349\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5658 - accuracy: 0.7655 - val_loss: 0.3802 - val_accuracy: 0.8532\n",
      "Epoch 55/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5012 - accuracy: 0.8118 - val_loss: 0.3324 - val_accuracy: 0.8624\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5085 - accuracy: 0.7936 - val_loss: 0.3156 - val_accuracy: 0.8899\n",
      "Epoch 57/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4414 - accuracy: 0.8309 - val_loss: 0.3533 - val_accuracy: 0.8807\n",
      "Epoch 58/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4764 - accuracy: 0.8347 - val_loss: 0.3608 - val_accuracy: 0.8624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5463 - accuracy: 0.7997 - val_loss: 0.3255 - val_accuracy: 0.8624\n",
      "Epoch 60/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5206 - accuracy: 0.7910 - val_loss: 0.3154 - val_accuracy: 0.8716\n",
      "Epoch 61/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4340 - accuracy: 0.8369 - val_loss: 0.3074 - val_accuracy: 0.8899\n",
      "Epoch 62/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.8433 - val_loss: 0.3439 - val_accuracy: 0.8440\n",
      "Epoch 63/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4350 - accuracy: 0.8145 - val_loss: 0.2989 - val_accuracy: 0.8532\n",
      "Epoch 64/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5052 - accuracy: 0.7916 - val_loss: 0.3117 - val_accuracy: 0.8716\n",
      "Epoch 65/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4630 - accuracy: 0.8415 - val_loss: 0.3404 - val_accuracy: 0.8716\n",
      "Epoch 66/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3456 - accuracy: 0.8508 - val_loss: 0.3027 - val_accuracy: 0.8899\n",
      "Epoch 67/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3578 - accuracy: 0.8723 - val_loss: 0.3472 - val_accuracy: 0.8532\n",
      "Epoch 68/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3524 - accuracy: 0.8534 - val_loss: 0.3524 - val_accuracy: 0.8349\n",
      "Epoch 69/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2971 - accuracy: 0.8845 - val_loss: 0.3400 - val_accuracy: 0.8349\n",
      "Epoch 70/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8804 - val_loss: 0.3217 - val_accuracy: 0.8899\n",
      "Epoch 71/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4260 - accuracy: 0.8351 - val_loss: 0.3272 - val_accuracy: 0.8899\n",
      "Epoch 72/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3245 - accuracy: 0.8753 - val_loss: 0.2769 - val_accuracy: 0.8899\n",
      "Epoch 73/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3436 - accuracy: 0.8636 - val_loss: 0.2657 - val_accuracy: 0.9083\n",
      "Epoch 74/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8743 - val_loss: 0.2835 - val_accuracy: 0.8807\n",
      "Epoch 75/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3369 - accuracy: 0.8739 - val_loss: 0.3547 - val_accuracy: 0.8807\n",
      "Epoch 76/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3584 - accuracy: 0.8799 - val_loss: 0.2695 - val_accuracy: 0.8991\n",
      "Epoch 77/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.8598 - val_loss: 0.2742 - val_accuracy: 0.8807\n",
      "Epoch 78/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3056 - accuracy: 0.8669 - val_loss: 0.2856 - val_accuracy: 0.8624\n",
      "Epoch 79/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.8613 - val_loss: 0.3575 - val_accuracy: 0.8624\n",
      "Epoch 80/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3576 - accuracy: 0.8641 - val_loss: 0.2829 - val_accuracy: 0.8716\n",
      "Epoch 81/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.8780 - val_loss: 0.3345 - val_accuracy: 0.8807\n",
      "Epoch 82/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3277 - accuracy: 0.8702 - val_loss: 0.2766 - val_accuracy: 0.8716\n",
      "Epoch 83/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.3223 - accuracy: 0.9103 - val_loss: 0.2890 - val_accuracy: 0.8899\n",
      "Epoch 84/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2791 - accuracy: 0.8971 - val_loss: 0.2888 - val_accuracy: 0.8899\n",
      "Epoch 85/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3597 - accuracy: 0.8840 - val_loss: 0.2870 - val_accuracy: 0.9083\n",
      "Epoch 86/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2821 - accuracy: 0.8944 - val_loss: 0.3216 - val_accuracy: 0.8807\n",
      "Epoch 87/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2948 - accuracy: 0.9113 - val_loss: 0.3117 - val_accuracy: 0.8807\n",
      "Epoch 88/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2921 - accuracy: 0.8982 - val_loss: 0.3057 - val_accuracy: 0.8716\n",
      "Epoch 89/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2569 - accuracy: 0.9216 - val_loss: 0.3139 - val_accuracy: 0.8899\n",
      "Epoch 90/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2458 - accuracy: 0.9156 - val_loss: 0.2977 - val_accuracy: 0.9174\n",
      "Epoch 91/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2306 - accuracy: 0.9243 - val_loss: 0.3234 - val_accuracy: 0.8807\n",
      "Epoch 92/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2978 - accuracy: 0.9082 - val_loss: 0.3375 - val_accuracy: 0.8807\n",
      "Epoch 93/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2621 - accuracy: 0.8887 - val_loss: 0.3129 - val_accuracy: 0.8807\n",
      "Epoch 94/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2116 - accuracy: 0.9004 - val_loss: 0.3524 - val_accuracy: 0.8624\n",
      "Epoch 95/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2902 - accuracy: 0.8935 - val_loss: 0.3251 - val_accuracy: 0.8716\n",
      "Epoch 96/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.8863 - val_loss: 0.2435 - val_accuracy: 0.8991\n",
      "Epoch 97/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3147 - accuracy: 0.8771 - val_loss: 0.2858 - val_accuracy: 0.8991\n",
      "Epoch 98/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3116 - accuracy: 0.8924 - val_loss: 0.2774 - val_accuracy: 0.9083\n",
      "Epoch 99/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2283 - accuracy: 0.9253 - val_loss: 0.2838 - val_accuracy: 0.8991\n",
      "Epoch 100/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2732 - accuracy: 0.8831 - val_loss: 0.2496 - val_accuracy: 0.9266\n",
      "Epoch 101/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2637 - accuracy: 0.9132 - val_loss: 0.2539 - val_accuracy: 0.9083\n",
      "Epoch 102/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2715 - accuracy: 0.9020 - val_loss: 0.2719 - val_accuracy: 0.8807\n",
      "Epoch 103/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2339 - accuracy: 0.9242 - val_loss: 0.2803 - val_accuracy: 0.9083\n",
      "Epoch 104/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2293 - accuracy: 0.9162 - val_loss: 0.2714 - val_accuracy: 0.9083\n",
      "Epoch 105/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2103 - accuracy: 0.9264 - val_loss: 0.2696 - val_accuracy: 0.8899\n",
      "Epoch 106/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2019 - accuracy: 0.9267 - val_loss: 0.2750 - val_accuracy: 0.8807\n",
      "Epoch 107/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1844 - accuracy: 0.9281 - val_loss: 0.2572 - val_accuracy: 0.9174\n",
      "Epoch 108/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1966 - accuracy: 0.9464 - val_loss: 0.3104 - val_accuracy: 0.9083\n",
      "Epoch 109/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1995 - accuracy: 0.9381 - val_loss: 0.2410 - val_accuracy: 0.9174\n",
      "Epoch 110/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2608 - accuracy: 0.9021 - val_loss: 0.3368 - val_accuracy: 0.8899\n",
      "Epoch 111/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2281 - accuracy: 0.9079 - val_loss: 0.2683 - val_accuracy: 0.9083\n",
      "Epoch 112/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2582 - accuracy: 0.9360 - val_loss: 0.3171 - val_accuracy: 0.8991\n",
      "Epoch 113/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2400 - accuracy: 0.9021 - val_loss: 0.3478 - val_accuracy: 0.8899\n",
      "Epoch 114/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2448 - accuracy: 0.9022 - val_loss: 0.3215 - val_accuracy: 0.8991\n",
      "Epoch 115/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2558 - accuracy: 0.9334 - val_loss: 0.3086 - val_accuracy: 0.9174\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2322 - accuracy: 0.9046 - val_loss: 0.3096 - val_accuracy: 0.8899\n",
      "Epoch 117/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1656 - accuracy: 0.9484 - val_loss: 0.2842 - val_accuracy: 0.9266\n",
      "Epoch 118/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2220 - accuracy: 0.9198 - val_loss: 0.2557 - val_accuracy: 0.9266\n",
      "Epoch 119/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1493 - accuracy: 0.9464 - val_loss: 0.2980 - val_accuracy: 0.8991\n",
      "Epoch 120/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2025 - accuracy: 0.9350 - val_loss: 0.2958 - val_accuracy: 0.8991\n",
      "Epoch 121/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2519 - accuracy: 0.9069 - val_loss: 0.3051 - val_accuracy: 0.9266\n",
      "Epoch 122/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1165 - accuracy: 0.9656 - val_loss: 0.2946 - val_accuracy: 0.9083\n",
      "Epoch 123/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2356 - accuracy: 0.9110 - val_loss: 0.2923 - val_accuracy: 0.9174\n",
      "Epoch 124/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1675 - accuracy: 0.9472 - val_loss: 0.2627 - val_accuracy: 0.9266\n",
      "Epoch 125/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2930 - accuracy: 0.9169 - val_loss: 0.2899 - val_accuracy: 0.9174\n",
      "Epoch 126/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2409 - accuracy: 0.9291 - val_loss: 0.2819 - val_accuracy: 0.8899\n",
      "Epoch 127/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1722 - accuracy: 0.9402 - val_loss: 0.3163 - val_accuracy: 0.8899\n",
      "Epoch 128/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2137 - accuracy: 0.9300 - val_loss: 0.3441 - val_accuracy: 0.9083\n",
      "Epoch 129/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1690 - accuracy: 0.9472 - val_loss: 0.3376 - val_accuracy: 0.8991\n",
      "Epoch 130/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2128 - accuracy: 0.9007 - val_loss: 0.2490 - val_accuracy: 0.9266\n",
      "Epoch 131/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2286 - accuracy: 0.9137 - val_loss: 0.2258 - val_accuracy: 0.9174\n",
      "Epoch 132/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3024 - accuracy: 0.9128 - val_loss: 0.2689 - val_accuracy: 0.9083\n",
      "Epoch 133/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2296 - accuracy: 0.9224 - val_loss: 0.2477 - val_accuracy: 0.9083\n",
      "Epoch 134/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2362 - accuracy: 0.9270 - val_loss: 0.3967 - val_accuracy: 0.8624\n",
      "Epoch 135/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2099 - accuracy: 0.9049 - val_loss: 0.2722 - val_accuracy: 0.8899\n",
      "Epoch 136/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1550 - accuracy: 0.9379 - val_loss: 0.2521 - val_accuracy: 0.9083\n",
      "Epoch 137/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2096 - accuracy: 0.9116 - val_loss: 0.3095 - val_accuracy: 0.8991\n",
      "Epoch 138/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3599 - accuracy: 0.8884 - val_loss: 0.2927 - val_accuracy: 0.8899\n",
      "Epoch 139/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2437 - accuracy: 0.9307 - val_loss: 0.3078 - val_accuracy: 0.9266\n",
      "Epoch 140/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2439 - accuracy: 0.9193 - val_loss: 0.2938 - val_accuracy: 0.9174\n",
      "Epoch 141/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2420 - accuracy: 0.9346 - val_loss: 0.2603 - val_accuracy: 0.9174\n",
      "Epoch 142/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2176 - accuracy: 0.9322 - val_loss: 0.3245 - val_accuracy: 0.8807\n",
      "Epoch 143/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1404 - accuracy: 0.9405 - val_loss: 0.2640 - val_accuracy: 0.9266\n",
      "Epoch 144/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1393 - accuracy: 0.9493 - val_loss: 0.2828 - val_accuracy: 0.9266\n",
      "Epoch 145/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1661 - accuracy: 0.9446 - val_loss: 0.2395 - val_accuracy: 0.9358\n",
      "Epoch 146/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1970 - accuracy: 0.9248 - val_loss: 0.2349 - val_accuracy: 0.9083\n",
      "Epoch 147/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1275 - accuracy: 0.9494 - val_loss: 0.2394 - val_accuracy: 0.9174\n",
      "Epoch 148/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1900 - accuracy: 0.9434 - val_loss: 0.2152 - val_accuracy: 0.9266\n",
      "Epoch 149/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1556 - accuracy: 0.9326 - val_loss: 0.2691 - val_accuracy: 0.9266\n",
      "Epoch 150/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1905 - accuracy: 0.9213 - val_loss: 0.2937 - val_accuracy: 0.9358\n",
      "Epoch 151/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1745 - accuracy: 0.9458 - val_loss: 0.3206 - val_accuracy: 0.8991\n",
      "Epoch 152/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2271 - accuracy: 0.9375 - val_loss: 0.2407 - val_accuracy: 0.9083\n",
      "Epoch 153/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1478 - accuracy: 0.9533 - val_loss: 0.2801 - val_accuracy: 0.9083\n",
      "Epoch 154/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2060 - accuracy: 0.9307 - val_loss: 0.2323 - val_accuracy: 0.9083\n",
      "Epoch 155/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2071 - accuracy: 0.9379 - val_loss: 0.2146 - val_accuracy: 0.9174\n",
      "Epoch 156/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2389 - accuracy: 0.9252 - val_loss: 0.2281 - val_accuracy: 0.9266\n",
      "Epoch 157/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2281 - accuracy: 0.9226 - val_loss: 0.2700 - val_accuracy: 0.9174\n",
      "Epoch 158/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1647 - accuracy: 0.9471 - val_loss: 0.2938 - val_accuracy: 0.9174\n",
      "Epoch 159/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3526 - accuracy: 0.9264 - val_loss: 0.1986 - val_accuracy: 0.9358\n",
      "Epoch 160/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.8867 - val_loss: 0.3354 - val_accuracy: 0.8807\n",
      "Epoch 161/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2736 - accuracy: 0.9132 - val_loss: 0.2165 - val_accuracy: 0.9358\n",
      "Epoch 162/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2140 - accuracy: 0.9101 - val_loss: 0.2948 - val_accuracy: 0.8991\n",
      "Epoch 163/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2534 - accuracy: 0.9006 - val_loss: 0.3387 - val_accuracy: 0.9174\n",
      "Epoch 164/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1709 - accuracy: 0.9429 - val_loss: 0.3656 - val_accuracy: 0.9083\n",
      "Epoch 165/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1312 - accuracy: 0.9547 - val_loss: 0.3429 - val_accuracy: 0.9174\n",
      "Epoch 166/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1625 - accuracy: 0.9444 - val_loss: 0.2686 - val_accuracy: 0.9266\n",
      "Epoch 167/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1245 - accuracy: 0.9514 - val_loss: 0.2165 - val_accuracy: 0.9358\n",
      "Epoch 168/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1888 - accuracy: 0.9200 - val_loss: 0.3126 - val_accuracy: 0.9174\n",
      "Epoch 169/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1175 - accuracy: 0.9643 - val_loss: 0.3615 - val_accuracy: 0.8991\n",
      "Epoch 170/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1150 - accuracy: 0.9587 - val_loss: 0.3194 - val_accuracy: 0.9083\n",
      "Epoch 171/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1438 - accuracy: 0.9573 - val_loss: 0.3023 - val_accuracy: 0.8991\n",
      "Epoch 172/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1244 - accuracy: 0.9692 - val_loss: 0.2877 - val_accuracy: 0.9083\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1085 - accuracy: 0.9762 - val_loss: 0.3195 - val_accuracy: 0.8991\n",
      "Epoch 174/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1937 - accuracy: 0.9403 - val_loss: 0.2229 - val_accuracy: 0.9266\n",
      "Epoch 175/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1364 - accuracy: 0.9538 - val_loss: 0.2503 - val_accuracy: 0.9174\n",
      "Epoch 176/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1350 - accuracy: 0.9527 - val_loss: 0.3066 - val_accuracy: 0.9174\n",
      "Epoch 177/200\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1614 - accuracy: 0.96 - 0s 6ms/step - loss: 0.1356 - accuracy: 0.9648 - val_loss: 0.3017 - val_accuracy: 0.9083\n",
      "Epoch 178/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1682 - accuracy: 0.9566 - val_loss: 0.3144 - val_accuracy: 0.8991\n",
      "Epoch 179/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3633 - accuracy: 0.9354 - val_loss: 0.2119 - val_accuracy: 0.9358\n",
      "Epoch 180/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1652 - accuracy: 0.9446 - val_loss: 0.2830 - val_accuracy: 0.9266\n",
      "Epoch 181/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1371 - accuracy: 0.9596 - val_loss: 0.4093 - val_accuracy: 0.9083\n",
      "Epoch 182/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1633 - accuracy: 0.9503 - val_loss: 0.2692 - val_accuracy: 0.9266\n",
      "Epoch 183/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2072 - accuracy: 0.9427 - val_loss: 0.1643 - val_accuracy: 0.9358\n",
      "Epoch 184/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1339 - accuracy: 0.9583 - val_loss: 0.2825 - val_accuracy: 0.8991\n",
      "Epoch 185/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0970 - accuracy: 0.9768 - val_loss: 0.3398 - val_accuracy: 0.9174\n",
      "Epoch 186/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2129 - accuracy: 0.9394 - val_loss: 0.2969 - val_accuracy: 0.9266\n",
      "Epoch 187/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1339 - accuracy: 0.9482 - val_loss: 0.3009 - val_accuracy: 0.9266\n",
      "Epoch 188/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1720 - accuracy: 0.9272 - val_loss: 0.3495 - val_accuracy: 0.9174\n",
      "Epoch 189/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2242 - accuracy: 0.9427 - val_loss: 0.4092 - val_accuracy: 0.8807\n",
      "Epoch 190/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1909 - accuracy: 0.9382 - val_loss: 0.2665 - val_accuracy: 0.9266\n",
      "Epoch 191/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0989 - accuracy: 0.9574 - val_loss: 0.4032 - val_accuracy: 0.9083\n",
      "Epoch 192/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0934 - accuracy: 0.9775 - val_loss: 0.2559 - val_accuracy: 0.9266\n",
      "Epoch 193/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0996 - accuracy: 0.9643 - val_loss: 0.3269 - val_accuracy: 0.9083\n",
      "Epoch 194/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1470 - accuracy: 0.9561 - val_loss: 0.3581 - val_accuracy: 0.9083\n",
      "Epoch 195/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1695 - accuracy: 0.9427 - val_loss: 0.3117 - val_accuracy: 0.9174\n",
      "Epoch 196/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0593 - accuracy: 0.9803 - val_loss: 0.3415 - val_accuracy: 0.9083\n",
      "Epoch 197/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1295 - accuracy: 0.9784 - val_loss: 0.2808 - val_accuracy: 0.9266\n",
      "Epoch 198/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0810 - accuracy: 0.9736 - val_loss: 0.3620 - val_accuracy: 0.9174\n",
      "Epoch 199/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2363 - accuracy: 0.9629 - val_loss: 0.3886 - val_accuracy: 0.9174\n",
      "Epoch 200/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1789 - accuracy: 0.9520 - val_loss: 0.2716 - val_accuracy: 0.9174\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0335 - accuracy: 0.9954\n",
      "Train Loss = 0.03348291665315628\n",
      "Train Accuracy = 0.9954022765159607\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.9174\n",
      "Test Loss = 0.2716318964958191\n",
      "Test Accuracy = 0.9174311757087708\n",
      "time: 18.041796922683716\n"
     ]
    }
   ],
   "source": [
    "#训练原始数据\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = LossHistory() # 创建一个history实例\n",
    "model.fit(X_train, Y_train, epochs=200, validation_data=(X_test, Y_test),batch_size=32,callbacks=[history])\n",
    "\n",
    "preds_train = model.evaluate(X_train, Y_train)\n",
    "print(\"Train Loss = \" + str(preds_train[0]))\n",
    "print(\"Train Accuracy = \" + str(preds_train[1]))\n",
    "\n",
    "preds_test  = model.evaluate(X_test, Y_test)\n",
    "print(\"Test Loss = \" + str(preds_test[0]))\n",
    "print(\"Test Accuracy = \" + str(preds_test[1]))\n",
    "end = time.time()\n",
    "print(\"time:\",end-start)\n",
    "\n",
    "#保存模型\n",
    "model.save('meg_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "supreme-galaxy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history.loss_plot('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-wesley",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
