{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mediterranean-jacksonville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End\n",
      "['forefinger1_processed.csv', 'forefinger2_processed.csv', 'forefinger3_processed.csv', 'forefinger4_processed.csv', 'indexfinger1_processed.csv', 'indexfinger2_processed.csv', 'indexfinger3_processed.csv', 'indexfinger4_processed.csv', 'littlefinger1_processed.csv', 'littlefinger2_processed.csv', 'littlefinger3_processed.csv', 'middlefinger1_processed.csv', 'middlefinger2_processed.csv', 'middlefinger3_processed.csv', 'thumb1_processed.csv', 'thumb2_processed.csv', 'thumb3_processed.csv', 'thumb4_processed.csv']\n"
     ]
    }
   ],
   "source": [
    "#Insert dataset\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import h5py\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, BatchNormalization,concatenate, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from emg import EMG_filter\n",
    "\n",
    "def get_files_in_directory(path, extension):\n",
    "    os.chdir(path)\n",
    "    result = glob.glob('*.{}'.format(extension))\n",
    "    result.sort() # Ensure correct order of files\n",
    "    return result\n",
    "def array_from_csv(file):\n",
    "    list_arr = pd.read_csv(file, sep=',', header=0,skiprows=2).values\n",
    "    return list_arr\n",
    "list_files = get_files_in_directory('C:/Users/Administrator/Desktop/MyoFile/dataset/', 'csv')\n",
    "print(list_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sharing-programmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(197, 120)\n",
      "(155,)\n"
     ]
    }
   ],
   "source": [
    "#Insert dataset, 截取, add label\n",
    "interval = 100\n",
    "data = []\n",
    "label = []\n",
    "for file in list_files:\n",
    "    dataset = array_from_csv(file)\n",
    "    emg = dataset[100:,0:5]\n",
    "    #emg2 = dataset[100:,2]\n",
    "    #截取数据\n",
    "    for j in range(0,len(emg)-len(emg)%interval,interval):\n",
    "        sample=[]\n",
    "        for i in range(interval):\n",
    "            channel = []\n",
    "            channel.append(emg[j+i][0])\n",
    "            channel.append(emg[j+i][1])\n",
    "            channel.append(emg[j+i][2])\n",
    "            channel.append(emg[j+i][3])\n",
    "            channel.append(emg[j+i][4])\n",
    "            sample.append(channel)\n",
    "        for i in range(120-interval):\n",
    "            sample.append([0,0,0])\n",
    "        data.append(sample)\n",
    "        if(\"thumb\" in file):\n",
    "            label.append(0)\n",
    "        elif(\"forefinger\" in file):\n",
    "            label.append(1)\n",
    "        elif(\"middlefinger\" in file):\n",
    "            label.append(2)\n",
    "        elif(\"indexfinger\" in file):\n",
    "            label.append(3)\n",
    "        elif(\"littlefinger\" in file):\n",
    "            label.append(4)\n",
    "data = np.asarray(data)\n",
    "label = np.asarray(label)\n",
    "print(data.shape)\n",
    "print(label.shape)        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indonesian-penetration",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-cde7ebb402e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "def convert_to_one_hot(Y,C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "#随机打乱数据和标签\n",
    "N = data.shape[0]\n",
    "index = np.random.permutation(N)\n",
    "data = data[index,:,:]\n",
    "label = label[index]\n",
    "\n",
    "#对数据升维，标签one-hot\n",
    "data = np.expand_dims(data,axis=3)\n",
    "label = convert_to_one_hot(label,5).T\n",
    "#划分数据集\n",
    "N = data.shape[0]\n",
    "num_train = round(N*0.8)\n",
    "X_train = data[0:num_train,:,:,:]\n",
    "Y_train = label[0:num_train,:]\n",
    "X_test = data[num_train:N,:,:,:]\n",
    "Y_test = label[num_train:N,:]\n",
    "\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aging-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "#写一个LossHistory类，保存loss和acc\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch':[], 'epoch':[]}\n",
    "        self.accuracy = {'batch':[], 'epoch':[]}\n",
    "        self.val_loss = {'batch':[], 'epoch':[]}\n",
    "        self.val_acc = {'batch':[], 'epoch':[]}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('acc'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('accuracy'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_accuracy'))\n",
    "\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        plt.figure()\n",
    "        # acc\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
    "        # loss\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "brilliant-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(input_shape=(120,3,1), classes=5): \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = Conv2D(filters=32, kernel_size=(20,3), strides=(1,1), activation='relu', padding='same')(X_input)\n",
    "    X = MaxPooling2D((20,1))(X)\n",
    "\n",
    "    X = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(X)\n",
    "    X = MaxPooling2D((2,1),)(X)\n",
    "    \n",
    "    X = Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu',padding='valid')(X)\n",
    "    \n",
    "    X = Flatten(name='flatten')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(128,activation='relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    model = Model(inputs=X_input, outputs=X)\n",
    "    return model\n",
    "    \n",
    "#model = CNN()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "valued-oliver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 120, 3, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 101, 1, 32)   1952        input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 105, 1, 32)   1568        input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 109, 1, 32)   1184        input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 113, 1, 32)   800         input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_93 (MaxPooling2D) (None, 6, 1, 32)     0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_95 (MaxPooling2D) (None, 6, 1, 32)     0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_97 (MaxPooling2D) (None, 6, 1, 32)     0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_99 (MaxPooling2D) (None, 6, 1, 32)     0           conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 4, 1, 64)     6208        max_pooling2d_93[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 3, 1, 64)     8256        max_pooling2d_95[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 2, 1, 64)     10304       max_pooling2d_97[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 1, 1, 64)     12352       max_pooling2d_99[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_94 (MaxPooling2D) (None, 1, 1, 64)     0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_96 (MaxPooling2D) (None, 1, 1, 64)     0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_98 (MaxPooling2D) (None, 1, 1, 64)     0           conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_100 (MaxPooling2D (None, 1, 1, 64)     0           conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 64)           0           max_pooling2d_94[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 64)           0           max_pooling2d_96[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 64)           0           max_pooling2d_98[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 64)           0           max_pooling2d_100[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 256)          0           flatten_31[0][0]                 \n",
      "                                                                 flatten_32[0][0]                 \n",
      "                                                                 flatten_33[0][0]                 \n",
      "                                                                 flatten_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 256)          0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 128)          32896       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 128)          0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 5)            645         dropout_15[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 76,165\n",
      "Trainable params: 76,165\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def ML_CNN(input_shape=(120,3,1), classes=5): \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    f1 = [20, 16, 12, 8]\n",
    "    f2 = [3, 4, 5, 6]\n",
    "    convs = []\n",
    "    \n",
    "    for i in range(4):\n",
    "        x = Conv2D(filters=32, kernel_size=(f1[i],3),strides=(1,1), activation='relu',padding='valid')(X_input)\n",
    "        x = MaxPooling2D((20,1),padding=\"SAME\")(x)\n",
    "        \n",
    "        x = Conv2D(filters=64, kernel_size=(f2[i],1), strides=(1,1), activation='relu', padding='valid')(x)\n",
    "        x = MaxPooling2D((9-2-i,1),padding=\"SAME\")(x)\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        convs.append(x)\n",
    "        \n",
    "    merge = concatenate(convs,axis=1)\n",
    "    X = merge\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(128,activation='relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    model = Model(inputs=X_input, outputs=X)\n",
    "    return model\n",
    "    \n",
    "model = ML_CNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "motivated-clear",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "9/9 [==============================] - 1s 23ms/step - loss: 8.6745 - accuracy: 0.2336 - val_loss: 3.8989 - val_accuracy: 0.2727\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 8.5436 - accuracy: 0.2799 - val_loss: 3.2193 - val_accuracy: 0.2879\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 3.7539 - accuracy: 0.4327 - val_loss: 2.1124 - val_accuracy: 0.3182\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 3.0655 - accuracy: 0.4452 - val_loss: 1.2868 - val_accuracy: 0.4394\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.8736 - accuracy: 0.5158 - val_loss: 1.0246 - val_accuracy: 0.5152\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.8138 - accuracy: 0.5262 - val_loss: 0.9255 - val_accuracy: 0.5606\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1.6872 - accuracy: 0.5139 - val_loss: 1.0119 - val_accuracy: 0.5606\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.5205 - accuracy: 0.5396 - val_loss: 0.9964 - val_accuracy: 0.5606\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 1.4954 - accuracy: 0.5358 - val_loss: 0.8685 - val_accuracy: 0.6212\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.3700 - accuracy: 0.5527 - val_loss: 0.7698 - val_accuracy: 0.6970\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.3534 - accuracy: 0.5579 - val_loss: 0.7398 - val_accuracy: 0.6818\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.3276 - accuracy: 0.5320 - val_loss: 0.8428 - val_accuracy: 0.5909\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.9953 - accuracy: 0.5995 - val_loss: 0.8431 - val_accuracy: 0.6364\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.1498 - accuracy: 0.5518 - val_loss: 0.7281 - val_accuracy: 0.6970\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.9221 - accuracy: 0.6186 - val_loss: 0.7321 - val_accuracy: 0.6970\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.9455 - accuracy: 0.6506 - val_loss: 0.7134 - val_accuracy: 0.7273\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.9235 - accuracy: 0.6164 - val_loss: 0.7429 - val_accuracy: 0.6970\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.8258 - accuracy: 0.6258 - val_loss: 0.7487 - val_accuracy: 0.6667\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.9220 - accuracy: 0.5954 - val_loss: 0.8052 - val_accuracy: 0.6364\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.8871 - accuracy: 0.6291 - val_loss: 0.8498 - val_accuracy: 0.6212\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.9210 - accuracy: 0.6210 - val_loss: 0.7169 - val_accuracy: 0.6970\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.9094 - accuracy: 0.6403 - val_loss: 0.6571 - val_accuracy: 0.7424\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.7770 - accuracy: 0.6635 - val_loss: 0.6557 - val_accuracy: 0.7576\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.9083 - accuracy: 0.6406 - val_loss: 0.6978 - val_accuracy: 0.6818\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.7869 - accuracy: 0.6990 - val_loss: 0.7450 - val_accuracy: 0.7424\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.7999 - accuracy: 0.6719 - val_loss: 0.7597 - val_accuracy: 0.7273\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.7159 - accuracy: 0.6731 - val_loss: 0.7312 - val_accuracy: 0.7424\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.7506 - accuracy: 0.6465 - val_loss: 0.6420 - val_accuracy: 0.7576\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.7712 - accuracy: 0.7078 - val_loss: 0.6640 - val_accuracy: 0.7121\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.7337 - accuracy: 0.6535 - val_loss: 0.7262 - val_accuracy: 0.6818\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.7896 - accuracy: 0.7222 - val_loss: 0.6686 - val_accuracy: 0.7576\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.7256 - accuracy: 0.6542 - val_loss: 0.6368 - val_accuracy: 0.8030\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.7547 - accuracy: 0.6669 - val_loss: 0.6358 - val_accuracy: 0.7879\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6772 - accuracy: 0.7314 - val_loss: 0.6111 - val_accuracy: 0.7879\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.7612 - accuracy: 0.6667 - val_loss: 0.6246 - val_accuracy: 0.8182\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.7446 - accuracy: 0.6918 - val_loss: 0.5633 - val_accuracy: 0.8485\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6069 - accuracy: 0.7313 - val_loss: 0.5619 - val_accuracy: 0.8333\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6660 - accuracy: 0.7360 - val_loss: 0.6045 - val_accuracy: 0.8030\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.7083 - accuracy: 0.7037 - val_loss: 0.6345 - val_accuracy: 0.8030\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6975 - accuracy: 0.6935 - val_loss: 0.6113 - val_accuracy: 0.7879\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5799 - accuracy: 0.7732 - val_loss: 0.6063 - val_accuracy: 0.8182\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6281 - accuracy: 0.7541 - val_loss: 0.6199 - val_accuracy: 0.8030\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5815 - accuracy: 0.7786 - val_loss: 0.5907 - val_accuracy: 0.8333\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5596 - accuracy: 0.7460 - val_loss: 0.5968 - val_accuracy: 0.7879\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5951 - accuracy: 0.7380 - val_loss: 0.5239 - val_accuracy: 0.8636\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5664 - accuracy: 0.7822 - val_loss: 0.5205 - val_accuracy: 0.8636\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5716 - accuracy: 0.7513 - val_loss: 0.5298 - val_accuracy: 0.8485\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5702 - accuracy: 0.7774 - val_loss: 0.5350 - val_accuracy: 0.8485\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6824 - accuracy: 0.7522 - val_loss: 0.5397 - val_accuracy: 0.8485\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5118 - accuracy: 0.7973 - val_loss: 0.5127 - val_accuracy: 0.8636\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4552 - accuracy: 0.8003 - val_loss: 0.5068 - val_accuracy: 0.8333\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5106 - accuracy: 0.7796 - val_loss: 0.4878 - val_accuracy: 0.8485\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5106 - accuracy: 0.7751 - val_loss: 0.5260 - val_accuracy: 0.8333\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5285 - accuracy: 0.8072 - val_loss: 0.5921 - val_accuracy: 0.7879\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6345 - accuracy: 0.7819 - val_loss: 0.5957 - val_accuracy: 0.8333\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5293 - accuracy: 0.7567 - val_loss: 0.6473 - val_accuracy: 0.8030\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4975 - accuracy: 0.7894 - val_loss: 0.6047 - val_accuracy: 0.8182\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4809 - accuracy: 0.8117 - val_loss: 0.5027 - val_accuracy: 0.8485\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.8050 - val_loss: 0.4893 - val_accuracy: 0.8788\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4738 - accuracy: 0.8360 - val_loss: 0.6007 - val_accuracy: 0.8333\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4295 - accuracy: 0.8347 - val_loss: 0.6171 - val_accuracy: 0.8485\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4913 - accuracy: 0.8136 - val_loss: 0.5532 - val_accuracy: 0.8636\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4409 - accuracy: 0.8591 - val_loss: 0.5467 - val_accuracy: 0.8636\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4135 - accuracy: 0.8358 - val_loss: 0.5335 - val_accuracy: 0.8636\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4286 - accuracy: 0.8248 - val_loss: 0.4648 - val_accuracy: 0.8788\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3904 - accuracy: 0.8534 - val_loss: 0.4100 - val_accuracy: 0.8788\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4659 - accuracy: 0.8035 - val_loss: 0.4114 - val_accuracy: 0.8788\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4317 - accuracy: 0.8321 - val_loss: 0.4112 - val_accuracy: 0.8788\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3439 - accuracy: 0.8838 - val_loss: 0.4463 - val_accuracy: 0.8788\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3826 - accuracy: 0.8331 - val_loss: 0.4420 - val_accuracy: 0.8788\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4686 - accuracy: 0.8052 - val_loss: 0.4858 - val_accuracy: 0.8333\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4455 - accuracy: 0.8544 - val_loss: 0.4375 - val_accuracy: 0.8788\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3957 - accuracy: 0.8249 - val_loss: 0.4357 - val_accuracy: 0.8636\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3081 - accuracy: 0.8851 - val_loss: 0.4902 - val_accuracy: 0.8333\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4005 - accuracy: 0.8435 - val_loss: 0.4976 - val_accuracy: 0.8636\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3613 - accuracy: 0.8377 - val_loss: 0.4682 - val_accuracy: 0.8939\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4034 - accuracy: 0.8339 - val_loss: 0.5204 - val_accuracy: 0.8485\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2896 - accuracy: 0.8832 - val_loss: 0.4728 - val_accuracy: 0.8485\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3037 - accuracy: 0.8749 - val_loss: 0.4515 - val_accuracy: 0.8788\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3524 - accuracy: 0.8662 - val_loss: 0.4247 - val_accuracy: 0.8939\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3553 - accuracy: 0.8428 - val_loss: 0.6490 - val_accuracy: 0.7879\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4736 - accuracy: 0.8233 - val_loss: 0.5058 - val_accuracy: 0.9091\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5492 - accuracy: 0.8125 - val_loss: 0.5106 - val_accuracy: 0.8636\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5998 - accuracy: 0.8138 - val_loss: 0.5985 - val_accuracy: 0.8030\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4162 - accuracy: 0.8559 - val_loss: 0.6356 - val_accuracy: 0.7879\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3307 - accuracy: 0.8522 - val_loss: 0.5099 - val_accuracy: 0.8636\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3117 - accuracy: 0.9001 - val_loss: 0.4811 - val_accuracy: 0.8939\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3333 - accuracy: 0.8614 - val_loss: 0.4990 - val_accuracy: 0.8788\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3261 - accuracy: 0.8718 - val_loss: 0.5648 - val_accuracy: 0.8485\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3192 - accuracy: 0.8842 - val_loss: 0.4993 - val_accuracy: 0.8333\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2772 - accuracy: 0.8675 - val_loss: 0.4400 - val_accuracy: 0.8939\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3967 - accuracy: 0.8770 - val_loss: 0.4335 - val_accuracy: 0.9091\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2958 - accuracy: 0.8819 - val_loss: 0.4762 - val_accuracy: 0.9091\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3075 - accuracy: 0.8663 - val_loss: 0.4582 - val_accuracy: 0.8636\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3799 - accuracy: 0.8481 - val_loss: 0.4501 - val_accuracy: 0.8788\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3535 - accuracy: 0.8770 - val_loss: 0.4857 - val_accuracy: 0.8788\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3603 - accuracy: 0.8454 - val_loss: 0.4496 - val_accuracy: 0.8485\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3338 - accuracy: 0.8594 - val_loss: 0.4516 - val_accuracy: 0.8788\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2968 - accuracy: 0.8687 - val_loss: 0.4861 - val_accuracy: 0.8939\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2725 - accuracy: 0.8868 - val_loss: 0.5592 - val_accuracy: 0.8788\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3256 - accuracy: 0.9096 - val_loss: 0.5402 - val_accuracy: 0.8636\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2329 - accuracy: 0.9168 - val_loss: 0.4695 - val_accuracy: 0.9091\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2383 - accuracy: 0.9062 - val_loss: 0.4428 - val_accuracy: 0.9091\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2659 - accuracy: 0.9283 - val_loss: 0.4744 - val_accuracy: 0.8636\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2274 - accuracy: 0.8995 - val_loss: 0.4996 - val_accuracy: 0.8788\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2516 - accuracy: 0.8982 - val_loss: 0.5267 - val_accuracy: 0.8636\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3530 - accuracy: 0.8875 - val_loss: 0.4847 - val_accuracy: 0.8939\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2293 - accuracy: 0.9206 - val_loss: 0.5493 - val_accuracy: 0.8485\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2338 - accuracy: 0.8940 - val_loss: 0.5544 - val_accuracy: 0.9091\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2024 - accuracy: 0.9202 - val_loss: 0.5838 - val_accuracy: 0.8939\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2344 - accuracy: 0.9211 - val_loss: 0.6987 - val_accuracy: 0.8485\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2760 - accuracy: 0.8984 - val_loss: 0.5950 - val_accuracy: 0.8788\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2433 - accuracy: 0.9348 - val_loss: 0.4667 - val_accuracy: 0.9091\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2202 - accuracy: 0.9365 - val_loss: 0.4491 - val_accuracy: 0.8788\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2272 - accuracy: 0.9244 - val_loss: 0.4741 - val_accuracy: 0.8788\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2208 - accuracy: 0.9279 - val_loss: 0.5667 - val_accuracy: 0.8939\n",
      "Epoch 117/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2183 - accuracy: 0.9129 - val_loss: 0.5335 - val_accuracy: 0.8939\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2021 - accuracy: 0.9205 - val_loss: 0.4780 - val_accuracy: 0.9091\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2202 - accuracy: 0.9138 - val_loss: 0.5689 - val_accuracy: 0.9091\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2220 - accuracy: 0.9331 - val_loss: 0.5875 - val_accuracy: 0.8939\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1875 - accuracy: 0.9332 - val_loss: 0.4899 - val_accuracy: 0.8788\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2316 - accuracy: 0.9087 - val_loss: 0.5237 - val_accuracy: 0.8485\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2241 - accuracy: 0.9324 - val_loss: 0.6489 - val_accuracy: 0.8636\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2221 - accuracy: 0.8953 - val_loss: 0.2659 - val_accuracy: 0.9242\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1956 - accuracy: 0.9236 - val_loss: 0.3153 - val_accuracy: 0.9091\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1573 - accuracy: 0.9612 - val_loss: 0.4024 - val_accuracy: 0.8636\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2018 - accuracy: 0.9344 - val_loss: 0.4882 - val_accuracy: 0.8636\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1187 - accuracy: 0.9576 - val_loss: 0.4696 - val_accuracy: 0.8939\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1678 - accuracy: 0.9381 - val_loss: 0.4541 - val_accuracy: 0.8939\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1571 - accuracy: 0.9530 - val_loss: 0.4653 - val_accuracy: 0.8636\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2258 - accuracy: 0.9322 - val_loss: 0.6183 - val_accuracy: 0.8788\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1933 - accuracy: 0.9289 - val_loss: 0.7533 - val_accuracy: 0.8788\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1447 - accuracy: 0.9390 - val_loss: 0.6566 - val_accuracy: 0.8939\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2168 - accuracy: 0.9087 - val_loss: 0.4956 - val_accuracy: 0.8939\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2386 - accuracy: 0.8966 - val_loss: 0.6126 - val_accuracy: 0.8788\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2092 - accuracy: 0.8960 - val_loss: 0.5209 - val_accuracy: 0.8939\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1037 - accuracy: 0.9817 - val_loss: 0.4163 - val_accuracy: 0.8939\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1513 - accuracy: 0.9405 - val_loss: 0.3528 - val_accuracy: 0.9091\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1583 - accuracy: 0.9312 - val_loss: 0.4772 - val_accuracy: 0.8939\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1486 - accuracy: 0.9489 - val_loss: 0.4623 - val_accuracy: 0.8939\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1121 - accuracy: 0.9575 - val_loss: 0.4894 - val_accuracy: 0.9091\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1165 - accuracy: 0.9501 - val_loss: 0.4904 - val_accuracy: 0.9091\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1218 - accuracy: 0.9597 - val_loss: 0.5155 - val_accuracy: 0.9091\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1597 - accuracy: 0.9401 - val_loss: 0.5352 - val_accuracy: 0.9091\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1273 - accuracy: 0.9581 - val_loss: 0.4799 - val_accuracy: 0.9091\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1469 - accuracy: 0.9427 - val_loss: 0.4819 - val_accuracy: 0.9091\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1847 - accuracy: 0.9378 - val_loss: 0.7010 - val_accuracy: 0.8788\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2027 - accuracy: 0.9267 - val_loss: 0.7106 - val_accuracy: 0.9091\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0962 - accuracy: 0.9721 - val_loss: 0.6170 - val_accuracy: 0.9091\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1264 - accuracy: 0.9652 - val_loss: 0.6640 - val_accuracy: 0.8636\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 0.9887\n",
      "Train Loss = 0.05808781087398529\n",
      "Train Accuracy = 0.9886792302131653\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6640 - accuracy: 0.8636\n",
      "Test Loss = 0.6639759540557861\n",
      "Test Accuracy = 0.8636363744735718\n",
      "time: 11.888205766677856\n"
     ]
    }
   ],
   "source": [
    "#训练原始数据\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = LossHistory() # 创建一个history实例\n",
    "model.fit(X_train, Y_train, epochs=150, validation_data=(X_test, Y_test),batch_size=32,callbacks=[history])\n",
    "\n",
    "preds_train = model.evaluate(X_train, Y_train)\n",
    "print(\"Train Loss = \" + str(preds_train[0]))\n",
    "print(\"Train Accuracy = \" + str(preds_train[1]))\n",
    "\n",
    "preds_test  = model.evaluate(X_test, Y_test)\n",
    "print(\"Test Loss = \" + str(preds_test[0]))\n",
    "print(\"Test Accuracy = \" + str(preds_test[1]))\n",
    "\n",
    "end = time.time()\n",
    "print(\"time:\",end-start)\n",
    "\n",
    "#保存模型\n",
    "model.save('meg_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "supreme-galaxy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history.loss_plot('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-wesley",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
