{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "honey-cartridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fist1.csv', 'fist2.csv', 'fist3.csv', 'forefinger1.csv', 'forefinger2.csv', 'forefinger3.csv', 'forefinger4.csv', 'forefinger5.csv', 'indexfinger1.csv', 'indexfinger2.csv', 'indexfinger3.csv', 'littlefinger1.csv', 'littlefinger2.csv', 'littlefinger3.csv', 'littlefinger4.csv', 'middlefinger1.csv', 'middlefinger2.csv', 'middlefinger3.csv', 'thumb1.csv', 'thumb2.csv', 'thumb3.csv']\n"
     ]
    }
   ],
   "source": [
    "#Insert dataset\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import h5py\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, BatchNormalization,concatenate, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from emg import EMG_filter\n",
    "\n",
    "def get_files_in_directory(path, extension):\n",
    "    os.chdir(path)\n",
    "    result = glob.glob('*.{}'.format(extension))\n",
    "    result.sort() # Ensure correct order of files\n",
    "    return result\n",
    "def array_from_csv(file):\n",
    "    list_arr = pd.read_csv(file, sep=',', header=0,skiprows=2).values\n",
    "    return list_arr\n",
    "list_files = get_files_in_directory('C:/Users/Administrator/Desktop/MyoFile/SignalTimeRecord/', 'csv')\n",
    "print(list_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "proved-lafayette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211, 120, 3)\n",
      "(211,)\n"
     ]
    }
   ],
   "source": [
    "#Insert dataset, 截取, add label\n",
    "interval = 100\n",
    "data = []\n",
    "label = []\n",
    "for file in list_files:\n",
    "    dataset = array_from_csv(file)\n",
    "    emg = dataset[100:,3:6]\n",
    "    #emg2 = dataset[100:,2]\n",
    "    #截取数据\n",
    "    for j in range(0,len(emg)-len(emg)%interval,interval):\n",
    "        sample=[]\n",
    "        for i in range(interval):\n",
    "            channel = []\n",
    "            channel.append(emg[j+i][0])\n",
    "            channel.append(emg[j+i][1])\n",
    "            channel.append(emg[j+i][2])\n",
    "            sample.append(channel)\n",
    "        for i in range(120-interval):\n",
    "            sample.append([0,0,0])\n",
    "        data.append(sample)\n",
    "        if(\"thumb\" in file):\n",
    "            label.append(0)\n",
    "        elif(\"forefinger\" in file):\n",
    "            label.append(1)\n",
    "        elif(\"middlefinger\" in file):\n",
    "            label.append(2)\n",
    "        elif(\"indexfinger\" in file):\n",
    "            label.append(3)\n",
    "        elif(\"littlefinger\" in file):\n",
    "            label.append(4)\n",
    "        elif(\"fist\" in file):\n",
    "            label.append(5)\n",
    "data = np.asarray(data)\n",
    "label = np.asarray(label)\n",
    "print(data.shape)\n",
    "print(label.shape)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "enclosed-cowboy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (169, 120, 3)\n",
      "Y_train shape: (169, 6)\n",
      "X_test shape: (42, 120, 3)\n",
      "Y_test shape: (42, 6)\n",
      "[[0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def convert_to_one_hot(Y,C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "#随机打乱数据和标签\n",
    "N = data.shape[0]\n",
    "index = np.random.permutation(N)\n",
    "data = data[index,:,:]\n",
    "label = label[index]\n",
    "\n",
    "#对数据升维，标签one-hot\n",
    "#data = np.expand_dims(data,axis=3)\n",
    "label = convert_to_one_hot(label,6).T\n",
    "#划分数据集\n",
    "N = data.shape[0]\n",
    "num_train = round(N*0.8)\n",
    "X_train = data[0:num_train,:,:]\n",
    "Y_train = label[0:num_train,:]\n",
    "X_test = data[num_train:N,:,:]\n",
    "Y_test = label[num_train:N,:]\n",
    "\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "affecting-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#写一个LossHistory类，保存loss和acc\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch':[], 'epoch':[]}\n",
    "        self.accuracy = {'batch':[], 'epoch':[]}\n",
    "        self.val_loss = {'batch':[], 'epoch':[]}\n",
    "        self.val_acc = {'batch':[], 'epoch':[]}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('acc'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('accuracy'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_accuracy'))\n",
    "\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        plt.figure()\n",
    "        # acc\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
    "        # loss\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "purple-campaign",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_CRNN(input_shape=(120,3,1), classes=6): \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    f1 = [20, 16, 12, 8]\n",
    "    f2 = [3, 4, 5, 6]\n",
    "    convs = []\n",
    "    \n",
    "    for i in range(4):\n",
    "        x = Conv2D(filters=32, kernel_size=(f1[i],3),strides=(1,1), activation='relu',padding='valid')(X_input)\n",
    "        x = MaxPooling2D((20,1),padding=\"SAME\")(x)\n",
    "        \n",
    "        x = Conv2D(filters=64, kernel_size=(f2[i],1), strides=(1,1), activation='relu', padding='valid')(x)\n",
    "        x = MaxPooling2D((9-2-i,1),padding=\"SAME\")(x)\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        convs.append(x)\n",
    "        \n",
    "    merge = concatenate(convs,axis=1)\n",
    "    X = merge\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(128,activation='relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    model = Model(inputs=X_input, outputs=X)\n",
    "    return model\n",
    "    \n",
    "#model = ML_CNN()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "optimum-disease",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 120, 3)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 120, 32)           1952      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 6, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 6, 64)             6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 3, 64)             0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 32)                3104      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 12,518\n",
      "Trainable params: 12,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def CRNN(input_shape=(120,3), classes=6): \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = Conv1D(filters=32, kernel_size=20, strides=1, activation='relu', padding='same')(X_input)\n",
    "    X = MaxPooling1D(20)(X)\n",
    "\n",
    "    X = Conv1D(filters=64, kernel_size=3, strides=1, activation='relu', padding='same')(X)\n",
    "    X = MaxPooling1D(2)(X)\n",
    "    \n",
    "    #X = SimpleRNN(units=32,activation='relu',input_shape=(3,64))(X)\n",
    "    #X = Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu',padding='valid')(X)\n",
    "    X = Flatten(name='flatten')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(32,activation='relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    model = Model(inputs=X_input, outputs=X)\n",
    "    return model\n",
    "    \n",
    "model = CRNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "chronic-snapshot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "6/6 [==============================] - 1s 49ms/step - loss: 58.7743 - accuracy: 0.2033 - val_loss: 8.1984 - val_accuracy: 0.2619\n",
      "Epoch 2/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 17.9206 - accuracy: 0.1586 - val_loss: 2.6645 - val_accuracy: 0.3095\n",
      "Epoch 3/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.4855 - accuracy: 0.1593 - val_loss: 2.3241 - val_accuracy: 0.2857\n",
      "Epoch 4/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.2813 - accuracy: 0.2565 - val_loss: 2.0679 - val_accuracy: 0.2143\n",
      "Epoch 5/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.6075 - accuracy: 0.1657 - val_loss: 1.9234 - val_accuracy: 0.2143\n",
      "Epoch 6/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.3056 - accuracy: 0.2008 - val_loss: 1.7030 - val_accuracy: 0.2143\n",
      "Epoch 7/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7923 - accuracy: 0.2094 - val_loss: 1.7032 - val_accuracy: 0.2143\n",
      "Epoch 8/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3044 - accuracy: 0.2394 - val_loss: 1.8028 - val_accuracy: 0.1429\n",
      "Epoch 9/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.9218 - accuracy: 0.1775 - val_loss: 1.7069 - val_accuracy: 0.1429\n",
      "Epoch 10/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7900 - accuracy: 0.2174 - val_loss: 1.7179 - val_accuracy: 0.2381\n",
      "Epoch 11/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.8355 - accuracy: 0.1883 - val_loss: 1.7253 - val_accuracy: 0.2143\n",
      "Epoch 12/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7704 - accuracy: 0.1575 - val_loss: 1.7268 - val_accuracy: 0.2143\n",
      "Epoch 13/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.8137 - accuracy: 0.2160 - val_loss: 1.7219 - val_accuracy: 0.2381\n",
      "Epoch 14/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7821 - accuracy: 0.2218 - val_loss: 1.7171 - val_accuracy: 0.2143\n",
      "Epoch 15/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6999 - accuracy: 0.2277 - val_loss: 1.7184 - val_accuracy: 0.2381\n",
      "Epoch 16/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7420 - accuracy: 0.2116 - val_loss: 1.7189 - val_accuracy: 0.3571\n",
      "Epoch 17/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6357 - accuracy: 0.2809 - val_loss: 1.7121 - val_accuracy: 0.2381\n",
      "Epoch 18/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7058 - accuracy: 0.2491 - val_loss: 1.7063 - val_accuracy: 0.2619\n",
      "Epoch 19/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6368 - accuracy: 0.2399 - val_loss: 1.7075 - val_accuracy: 0.2857\n",
      "Epoch 20/150\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.6910 - accuracy: 0.2596 - val_loss: 1.7100 - val_accuracy: 0.3095\n",
      "Epoch 21/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7308 - accuracy: 0.2390 - val_loss: 1.7026 - val_accuracy: 0.2857\n",
      "Epoch 22/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6747 - accuracy: 0.2329 - val_loss: 1.6946 - val_accuracy: 0.3333\n",
      "Epoch 23/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7287 - accuracy: 0.2344 - val_loss: 1.6906 - val_accuracy: 0.3333\n",
      "Epoch 24/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6202 - accuracy: 0.2639 - val_loss: 1.6875 - val_accuracy: 0.3333\n",
      "Epoch 25/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.6879 - accuracy: 0.2393 - val_loss: 1.6832 - val_accuracy: 0.3333\n",
      "Epoch 26/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.6518 - accuracy: 0.2352 - val_loss: 1.6790 - val_accuracy: 0.3810\n",
      "Epoch 27/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6747 - accuracy: 0.2295 - val_loss: 1.6884 - val_accuracy: 0.3810\n",
      "Epoch 28/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6565 - accuracy: 0.2674 - val_loss: 1.7110 - val_accuracy: 0.3571\n",
      "Epoch 29/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6737 - accuracy: 0.2727 - val_loss: 1.7004 - val_accuracy: 0.3571\n",
      "Epoch 30/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.6815 - accuracy: 0.2363 - val_loss: 1.6671 - val_accuracy: 0.4048\n",
      "Epoch 31/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6599 - accuracy: 0.2921 - val_loss: 1.6545 - val_accuracy: 0.4048\n",
      "Epoch 32/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6314 - accuracy: 0.2900 - val_loss: 1.6685 - val_accuracy: 0.3810\n",
      "Epoch 33/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5775 - accuracy: 0.3130 - val_loss: 1.6940 - val_accuracy: 0.3571\n",
      "Epoch 34/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7310 - accuracy: 0.3329 - val_loss: 1.6566 - val_accuracy: 0.4286\n",
      "Epoch 35/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7598 - accuracy: 0.3017 - val_loss: 1.6619 - val_accuracy: 0.4286\n",
      "Epoch 36/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6717 - accuracy: 0.3156 - val_loss: 1.6705 - val_accuracy: 0.4048\n",
      "Epoch 37/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.8300 - accuracy: 0.2811 - val_loss: 1.6734 - val_accuracy: 0.3571\n",
      "Epoch 38/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7304 - accuracy: 0.2724 - val_loss: 1.6740 - val_accuracy: 0.3571\n",
      "Epoch 39/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6677 - accuracy: 0.2846 - val_loss: 1.6597 - val_accuracy: 0.3571\n",
      "Epoch 40/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6503 - accuracy: 0.2407 - val_loss: 1.6608 - val_accuracy: 0.3571\n",
      "Epoch 41/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5996 - accuracy: 0.2506 - val_loss: 1.6535 - val_accuracy: 0.4048\n",
      "Epoch 42/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5823 - accuracy: 0.3141 - val_loss: 1.6458 - val_accuracy: 0.4048\n",
      "Epoch 43/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5892 - accuracy: 0.3249 - val_loss: 1.6572 - val_accuracy: 0.4286\n",
      "Epoch 44/150\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.5470 - accuracy: 0.28 - 0s 8ms/step - loss: 1.6348 - accuracy: 0.2840 - val_loss: 1.7684 - val_accuracy: 0.4286\n",
      "Epoch 45/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7162 - accuracy: 0.2742 - val_loss: 1.9161 - val_accuracy: 0.4286\n",
      "Epoch 46/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6859 - accuracy: 0.3400 - val_loss: 1.6072 - val_accuracy: 0.4286\n",
      "Epoch 47/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6157 - accuracy: 0.2852 - val_loss: 1.6030 - val_accuracy: 0.4286\n",
      "Epoch 48/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6207 - accuracy: 0.3327 - val_loss: 1.6140 - val_accuracy: 0.4048\n",
      "Epoch 49/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6413 - accuracy: 0.3026 - val_loss: 1.6327 - val_accuracy: 0.3810\n",
      "Epoch 50/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6476 - accuracy: 0.2277 - val_loss: 1.6323 - val_accuracy: 0.4048\n",
      "Epoch 51/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6733 - accuracy: 0.2724 - val_loss: 1.6407 - val_accuracy: 0.4048\n",
      "Epoch 52/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5918 - accuracy: 0.3511 - val_loss: 1.6469 - val_accuracy: 0.4048\n",
      "Epoch 53/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5899 - accuracy: 0.3559 - val_loss: 1.6494 - val_accuracy: 0.4048\n",
      "Epoch 54/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.6048 - accuracy: 0.3275 - val_loss: 1.6416 - val_accuracy: 0.4048\n",
      "Epoch 55/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6071 - accuracy: 0.3317 - val_loss: 1.6533 - val_accuracy: 0.3571\n",
      "Epoch 56/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5843 - accuracy: 0.2703 - val_loss: 1.6360 - val_accuracy: 0.4048\n",
      "Epoch 57/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5016 - accuracy: 0.3457 - val_loss: 1.6197 - val_accuracy: 0.4286\n",
      "Epoch 58/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5720 - accuracy: 0.3236 - val_loss: 1.6092 - val_accuracy: 0.4524\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6698 - accuracy: 0.2844 - val_loss: 1.6231 - val_accuracy: 0.4524\n",
      "Epoch 60/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5523 - accuracy: 0.3317 - val_loss: 1.5924 - val_accuracy: 0.4286\n",
      "Epoch 61/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5460 - accuracy: 0.3263 - val_loss: 1.5869 - val_accuracy: 0.4524\n",
      "Epoch 62/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.5551 - accuracy: 0.3330 - val_loss: 1.5915 - val_accuracy: 0.4524\n",
      "Epoch 63/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5974 - accuracy: 0.3312 - val_loss: 1.5955 - val_accuracy: 0.4524\n",
      "Epoch 64/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5801 - accuracy: 0.2821 - val_loss: 1.5916 - val_accuracy: 0.4524\n",
      "Epoch 65/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5602 - accuracy: 0.3229 - val_loss: 1.6307 - val_accuracy: 0.4524\n",
      "Epoch 66/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5247 - accuracy: 0.3490 - val_loss: 1.5789 - val_accuracy: 0.4524\n",
      "Epoch 67/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5935 - accuracy: 0.3262 - val_loss: 1.5784 - val_accuracy: 0.4524\n",
      "Epoch 68/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6017 - accuracy: 0.3249 - val_loss: 1.5891 - val_accuracy: 0.4524\n",
      "Epoch 69/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5154 - accuracy: 0.3487 - val_loss: 1.6021 - val_accuracy: 0.4524\n",
      "Epoch 70/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5406 - accuracy: 0.3365 - val_loss: 1.6003 - val_accuracy: 0.4286\n",
      "Epoch 71/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5657 - accuracy: 0.3293 - val_loss: 1.5855 - val_accuracy: 0.4286\n",
      "Epoch 72/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5217 - accuracy: 0.3964 - val_loss: 1.5684 - val_accuracy: 0.4524\n",
      "Epoch 73/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.4799 - accuracy: 0.3774 - val_loss: 1.5532 - val_accuracy: 0.4286\n",
      "Epoch 74/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5482 - accuracy: 0.3316 - val_loss: 1.5420 - val_accuracy: 0.4286\n",
      "Epoch 75/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7043 - accuracy: 0.3248 - val_loss: 1.5483 - val_accuracy: 0.4286\n",
      "Epoch 76/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.4853 - accuracy: 0.3451 - val_loss: 1.5441 - val_accuracy: 0.4524\n",
      "Epoch 77/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.5343 - accuracy: 0.3641 - val_loss: 1.5462 - val_accuracy: 0.4286\n",
      "Epoch 78/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5745 - accuracy: 0.2946 - val_loss: 1.5459 - val_accuracy: 0.4286\n",
      "Epoch 79/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5652 - accuracy: 0.3287 - val_loss: 1.5547 - val_accuracy: 0.4286\n",
      "Epoch 80/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5497 - accuracy: 0.3433 - val_loss: 1.5779 - val_accuracy: 0.4286\n",
      "Epoch 81/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5812 - accuracy: 0.3121 - val_loss: 1.5738 - val_accuracy: 0.4286\n",
      "Epoch 82/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5311 - accuracy: 0.3577 - val_loss: 1.5680 - val_accuracy: 0.4524\n",
      "Epoch 83/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.5372 - accuracy: 0.4126 - val_loss: 1.5495 - val_accuracy: 0.4286\n",
      "Epoch 84/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.5762 - accuracy: 0.3302 - val_loss: 1.5285 - val_accuracy: 0.4286\n",
      "Epoch 85/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5947 - accuracy: 0.2974 - val_loss: 1.5264 - val_accuracy: 0.4286\n",
      "Epoch 86/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5263 - accuracy: 0.2906 - val_loss: 1.5312 - val_accuracy: 0.4286\n",
      "Epoch 87/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.4446 - accuracy: 0.3709 - val_loss: 1.5349 - val_accuracy: 0.4286\n",
      "Epoch 88/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.5061 - accuracy: 0.3448 - val_loss: 1.5382 - val_accuracy: 0.4286\n",
      "Epoch 89/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3906 - accuracy: 0.3735 - val_loss: 1.5421 - val_accuracy: 0.4286\n",
      "Epoch 90/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5317 - accuracy: 0.3287 - val_loss: 1.5552 - val_accuracy: 0.4524\n",
      "Epoch 91/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4728 - accuracy: 0.3785 - val_loss: 1.5990 - val_accuracy: 0.3810\n",
      "Epoch 92/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5192 - accuracy: 0.3471 - val_loss: 1.5775 - val_accuracy: 0.4524\n",
      "Epoch 93/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5021 - accuracy: 0.3896 - val_loss: 1.5795 - val_accuracy: 0.4524\n",
      "Epoch 94/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5374 - accuracy: 0.3503 - val_loss: 1.5739 - val_accuracy: 0.4524\n",
      "Epoch 95/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5068 - accuracy: 0.4077 - val_loss: 1.5415 - val_accuracy: 0.4524\n",
      "Epoch 96/150\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.5226 - accuracy: 0.3870 - val_loss: 1.5249 - val_accuracy: 0.4286\n",
      "Epoch 97/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5062 - accuracy: 0.3657 - val_loss: 1.5150 - val_accuracy: 0.4524\n",
      "Epoch 98/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.5266 - accuracy: 0.3145 - val_loss: 1.5302 - val_accuracy: 0.4286\n",
      "Epoch 99/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4558 - accuracy: 0.4289 - val_loss: 1.5321 - val_accuracy: 0.4286\n",
      "Epoch 100/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4891 - accuracy: 0.3824 - val_loss: 1.5376 - val_accuracy: 0.4286\n",
      "Epoch 101/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4540 - accuracy: 0.3967 - val_loss: 1.5273 - val_accuracy: 0.4286\n",
      "Epoch 102/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4480 - accuracy: 0.4001 - val_loss: 1.5168 - val_accuracy: 0.4286\n",
      "Epoch 103/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5004 - accuracy: 0.3985 - val_loss: 1.5150 - val_accuracy: 0.4286\n",
      "Epoch 104/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5469 - accuracy: 0.3973 - val_loss: 1.5145 - val_accuracy: 0.4286\n",
      "Epoch 105/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5101 - accuracy: 0.3627 - val_loss: 1.5457 - val_accuracy: 0.4286\n",
      "Epoch 106/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5816 - accuracy: 0.3369 - val_loss: 1.5315 - val_accuracy: 0.4524\n",
      "Epoch 107/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4640 - accuracy: 0.4022 - val_loss: 1.5167 - val_accuracy: 0.4286\n",
      "Epoch 108/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4046 - accuracy: 0.4471 - val_loss: 1.5124 - val_accuracy: 0.4286\n",
      "Epoch 109/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6298 - accuracy: 0.3058 - val_loss: 1.5018 - val_accuracy: 0.4286\n",
      "Epoch 110/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5385 - accuracy: 0.3020 - val_loss: 1.5583 - val_accuracy: 0.4286\n",
      "Epoch 111/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4908 - accuracy: 0.3792 - val_loss: 1.6070 - val_accuracy: 0.4286\n",
      "Epoch 112/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5252 - accuracy: 0.3751 - val_loss: 1.5994 - val_accuracy: 0.4048\n",
      "Epoch 113/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.5513 - accuracy: 0.3832 - val_loss: 1.5910 - val_accuracy: 0.4048\n",
      "Epoch 114/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5292 - accuracy: 0.3639 - val_loss: 1.5770 - val_accuracy: 0.4524\n",
      "Epoch 115/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4491 - accuracy: 0.4082 - val_loss: 1.5642 - val_accuracy: 0.4762\n",
      "Epoch 116/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4614 - accuracy: 0.4283 - val_loss: 1.5539 - val_accuracy: 0.5000\n",
      "Epoch 117/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5381 - accuracy: 0.3649 - val_loss: 1.5271 - val_accuracy: 0.5000\n",
      "Epoch 118/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3491 - accuracy: 0.4524 - val_loss: 1.6118 - val_accuracy: 0.4524\n",
      "Epoch 119/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4291 - accuracy: 0.3907 - val_loss: 1.6285 - val_accuracy: 0.4524\n",
      "Epoch 120/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4471 - accuracy: 0.4136 - val_loss: 1.6353 - val_accuracy: 0.4524\n",
      "Epoch 121/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5425 - accuracy: 0.3503 - val_loss: 1.5298 - val_accuracy: 0.4524\n",
      "Epoch 122/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4831 - accuracy: 0.4385 - val_loss: 1.5244 - val_accuracy: 0.4524\n",
      "Epoch 123/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.4432 - accuracy: 0.4044 - val_loss: 1.4981 - val_accuracy: 0.4524\n",
      "Epoch 124/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.4353 - accuracy: 0.3727 - val_loss: 1.4805 - val_accuracy: 0.4762\n",
      "Epoch 125/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4942 - accuracy: 0.3726 - val_loss: 1.4769 - val_accuracy: 0.4762\n",
      "Epoch 126/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4300 - accuracy: 0.4180 - val_loss: 1.5957 - val_accuracy: 0.5000\n",
      "Epoch 127/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.5629 - accuracy: 0.3703 - val_loss: 1.5445 - val_accuracy: 0.5000\n",
      "Epoch 128/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3808 - accuracy: 0.4186 - val_loss: 1.5522 - val_accuracy: 0.5000\n",
      "Epoch 129/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4271 - accuracy: 0.3796 - val_loss: 1.7816 - val_accuracy: 0.4762\n",
      "Epoch 130/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4265 - accuracy: 0.4066 - val_loss: 1.8220 - val_accuracy: 0.5000\n",
      "Epoch 131/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4841 - accuracy: 0.3856 - val_loss: 1.5923 - val_accuracy: 0.5000\n",
      "Epoch 132/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3940 - accuracy: 0.4511 - val_loss: 1.7772 - val_accuracy: 0.4286\n",
      "Epoch 133/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4608 - accuracy: 0.3811 - val_loss: 1.5130 - val_accuracy: 0.4524\n",
      "Epoch 134/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.4680 - accuracy: 0.4192 - val_loss: 1.6182 - val_accuracy: 0.4048\n",
      "Epoch 135/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.7572 - accuracy: 0.3286 - val_loss: 1.6315 - val_accuracy: 0.3571\n",
      "Epoch 136/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6031 - accuracy: 0.3155 - val_loss: 1.6080 - val_accuracy: 0.3810\n",
      "Epoch 137/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5181 - accuracy: 0.3757 - val_loss: 1.5709 - val_accuracy: 0.4524\n",
      "Epoch 138/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.4666 - accuracy: 0.3656 - val_loss: 1.6040 - val_accuracy: 0.4048\n",
      "Epoch 139/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.5443 - accuracy: 0.3633 - val_loss: 1.6052 - val_accuracy: 0.4048\n",
      "Epoch 140/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5080 - accuracy: 0.3371 - val_loss: 1.5490 - val_accuracy: 0.4048\n",
      "Epoch 141/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4060 - accuracy: 0.4158 - val_loss: 1.5557 - val_accuracy: 0.4762\n",
      "Epoch 142/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4833 - accuracy: 0.3972 - val_loss: 1.5640 - val_accuracy: 0.4286\n",
      "Epoch 143/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5226 - accuracy: 0.3680 - val_loss: 1.5940 - val_accuracy: 0.3810\n",
      "Epoch 144/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5261 - accuracy: 0.4536 - val_loss: 1.5482 - val_accuracy: 0.4286\n",
      "Epoch 145/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3826 - accuracy: 0.4521 - val_loss: 1.5139 - val_accuracy: 0.4524\n",
      "Epoch 146/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4549 - accuracy: 0.4366 - val_loss: 1.5211 - val_accuracy: 0.4286\n",
      "Epoch 147/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3666 - accuracy: 0.4278 - val_loss: 1.5143 - val_accuracy: 0.4524\n",
      "Epoch 148/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4638 - accuracy: 0.4174 - val_loss: 1.4967 - val_accuracy: 0.4762\n",
      "Epoch 149/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3670 - accuracy: 0.4401 - val_loss: 1.5400 - val_accuracy: 0.4048\n",
      "Epoch 150/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.5243 - accuracy: 0.4212 - val_loss: 1.4954 - val_accuracy: 0.4762\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.1918 - accuracy: 0.5444\n",
      "Train Loss = 1.1918120384216309\n",
      "Train Accuracy = 0.5443786978721619\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4954 - accuracy: 0.4762\n",
      "Test Loss = 1.4953536987304688\n",
      "Test Accuracy = 0.4761904776096344\n",
      "time: 7.970700025558472\n"
     ]
    }
   ],
   "source": [
    "#训练原始数据\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = LossHistory() # 创建一个history实例\n",
    "model.fit(X_train, Y_train, epochs=150, validation_data=(X_test, Y_test),batch_size=32,callbacks=[history])\n",
    "\n",
    "preds_train = model.evaluate(X_train, Y_train)\n",
    "print(\"Train Loss = \" + str(preds_train[0]))\n",
    "print(\"Train Accuracy = \" + str(preds_train[1]))\n",
    "\n",
    "preds_test  = model.evaluate(X_test, Y_test)\n",
    "print(\"Test Loss = \" + str(preds_test[0]))\n",
    "print(\"Test Accuracy = \" + str(preds_test[1]))\n",
    "\n",
    "end = time.time()\n",
    "print(\"time:\",end-start)\n",
    "\n",
    "#保存模型\n",
    "model.save('meg_rnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.loss_plot('epoch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
